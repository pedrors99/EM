---
title: "Práctica 1.2. Análisis de componentes principales (ACP)"
author: "© José Luis Romero Béjar"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  word_document:
    toc: yes
    toc_depth: '3'
  html_document:
    toc: yes
    toc_depth: 3
    number_sections: no
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---
<style>
.math {
  font-size: 8.25pt;options(encoding = 'UTF-8')
}
</style>

<div style="text-align: justify">
---
© Este material está protegido por la **Licencia Creative Commons CC BY-NC-ND** que permite *descargar las obras y compartirlas con otras personas, siempre que se reconozca su autoría, pero no se pueden cambiar de ninguna manera ni se pueden utilizar comercialmente*.


En este guión breve se realiza un segundo ejemplo de reducción de la dimensión en un conjunto de datos  mediante el uso del **Lenguaje R**. Para la realización de esta práctica hay que descargar los archivos disponibles en la plataforma PRADO de la asignatura:

+ *Practica_1.2_ACP.Rmd*
+ *Datos_mundiales.sav*

**En esta práctica se incidirá en:**

+ Realizar un **análisis exploratorio** previo de los datos para identificar posibles **datos perdidos** y **valores extremos**.
+ **Tomar decisiones** y tratar datos perdidos y valores extremos.
+ Realizar un **ACP**.
+ Elección del **número óptimo** de componentes principales.
+ Interpretación de distintas salidas gráficas de interés para este método.
+ **Lenguaje R**: notebook **RMarkdown**, carga de ficheros de datos externos, métodos **apply, tapply, width, by**, etc. para la depuración de funciones.
+ Hacia el **informe final**.




### 1. **Pre-procesamiento de los datos**

### 1.0. *Descripción de la base de datos*
El fichero *Datos_mundiales.sav* contiene, entre otras, a las variables *znac_def, zmortinf, zfertil, zinc_pob, tasa_na, zurbana, zalfabet, zcaloría, zlog_pib, zpib_cap, zpoblac, zdensida*, que son las variables estandarizadas de las originales de igual denominación pero sin la *z* inicial, y que respectivamente son los valores para cada país del mundo de:

+ Tasa Nacimientos/Defunciones (nac_def)
+ Mortalidad infantil: muertes por 1000 nacimientos vivos (mortinf)
+ Fertilidad: número promedio de hijos (fertil)
+ Aumento de la población en % anual (inc_pob)
+ Tasa de natalidad por 1.000 habitantes (tasa_na)
+ Habitantes en ciudades en % (urbana)
+ Personas Alfabetizadas en % (alfabet)
+ Ingesta diaria de calorías (calorías)
+ Log(10) de PIB_CAP (log_pib)
+ Producto interior bruto per-capita (pib_cap)
+ Población en miles (poblac)
+ Habitantes por Km2 (densidad)  

### 1.1. *Carga de datos desde un fichero local*
El archivo de datos tiene extensión *.sav* que indica que se ha creado con el software SPSS. Para la carga del fichero utilizaremos la función *read.spss* dentro del paquete *foreign*. 

Es importante advertir que si se quiere evitar pasar la ruta local completa del archivo de datos, es conveniente que la sesión de R actual se esté ejecutando en el mismo directorio en el que se encuentra el fichero. Si no es así, se puede modificar en tiempo de ejecución con la función *setwd("Ubicación del archivo de datos")*. Otra forma de modificar esta ruta es desde la barra de menús de RStudio pulsando *Session/Set Working Directory/Choose Directory*. Si asumimos que nuestra sesión de R está correctamente direccionada, el siguiente código carga el fichero de datos en un data.frame.

```{r echo=TRUE, include=TRUE, warning=FALSE}
library(foreign)
datos<-read.spss("Datos_mundiales.sav", to.data.frame = TRUE, check.names = F)
```  
Si se visualiza el data.frame se advierte que las variables de la 1 a la 31 no se van a utilizar porque se trabaja con los datos estandarizados. El código siguiente limpia los datos para construir un data.frame que tan solo incluye las variables de interés.

```{r echo=TRUE, include=TRUE, warning=FALSE}
# Se eliminan las 31 primeras variables.
datos_pca<-datos[,-(1:31)]

# Las dos últimas variables parecen duplicadas o con información irrelevante.
datos_pca<-datos_pca[,-(16:17)]

# Se guardan los datos en un data.frame auxiliar para mantenerlos cargados
datos_originales<-datos_pca

# Se muestran los tres primeros registros de la base de datos
head(datos_pca,n=3)
```  

Se observa que esta base de datos tiene bastantes valores perdidos en distintas variables. Estos datos *NA* hay que tratarlos con cuidado. El siguiente epígrafe muestra un ejemplo de su tratamiento.

### 1.2. *Identificación y tratamiento de valores perdidos (NA)*
El siguiente código fuente define una función que identifica valores perdidos y los sustituye por la media de los valores de la variable que contiene estos valores. Esta decisión se ha tomado asumiendo que el comportamiento de los *NA* es totalmente aleatorio (esto habría que analizado en profundidad para confirmar esta decisión tomada). 

```{r echo=TRUE, include=TRUE, warning=FALSE}
# Construcción de la variable que trata los valores perdidos
not_available<-function(data,na.rm=F){
  data[is.na(data)]<-mean(data,na.rm=T)
  data
}

# Llamamos a la función not_available para cada variable de la base de datos
datos_pca$znac_def<-not_available(datos_pca$znac_def)
datos_pca$zmortinf<-not_available(datos_pca$zmortinf)
datos_pca$zfertil<-not_available(datos_pca$zfertil)
datos_pca$zinc_pob<-not_available(datos_pca$zinc_pob)
datos_pca$ztasa_na<-not_available(datos_pca$ztasa_na)
datos_pca$zurbana<-not_available(datos_pca$zurbana)
datos_pca$zespvida<-not_available(datos_pca$zespvida)
datos_pca$zalfabet<-not_available(datos_pca$zalfabet)
datos_pca$zcaloría<-not_available(datos_pca$zcaloría)
datos_pca$zlog_pib<-not_available(datos_pca$zlog_pib)
datos_pca$zpib_cap<-not_available(datos_pca$zpib_cap)
datos_pca$zpoblac<-not_available(datos_pca$zpoblac)
datos_pca$zdensida<-not_available(datos_pca$zdensida)
datos_pca$zlog_pob<-not_available(datos_pca$zlog_pob)
datos_pca$zlogden<-not_available(datos_pca$zlogden)

# Visualizamos nuevamente los datos
head(datos_pca,n=3)
```

### 2. **¿Tiene sentido un ACP?**

### 2.1. *Correlación*

En primer lugar es necesario confirmar que las variables no son independientes. A nivel de la muestra recogida en la base de datos esta comprobación se puede hacer calculando y observando la matriz de correlaciones. A nivel poblacional justificaremos que hay correlación realizando el test de Bartlett (El contraste de esfericidad de Bartlett permite comprobar si las correlaciones son distintas de 0 de modo significativo. La hipótesis nula es que $det(R)=1$). El siguiente código fuente realiza las dos comprobaciones indicadas.

```{r echo=TRUE, include=TRUE, warning=FALSE}
# Matriz de correlaciones.
cor(datos_pca)

# Test de Bartlett
# Si la librería psych no está instalada habría que hacerlo con la orden 
# install.packages("psych")
library(psych)
# Se normalizan los datos
datos_normalizados<-scale(datos_pca)
# Se hace el test de esfericidad
cortest.bartlett(cor(datos_normalizados))
``` 
A la vista de los resultados del test ($\chi^2(105)=1812.44; p<0.001$) podemos afirmar que los datos no son independientes y, por tanto, tiene sentido plantearse una reducción de la dimensión mediante el procedimiento de Análisis de Componentes Principales (ACP).

### 2.2. *Tratamiento de outliers*
El análisis de componentes principales es muy sensible a la presencia de valores atípicos (outliers) en alguna/s de sus variables. El siguiente código realiza un análisis exploratorio gráfico mediante la construcción de todos los boxplots de todas las variables para detectar la presencia de estos valores atípicos. Una vez los detecta se toma la decisión de sustituirlos por su media mediante la construcción de una función, outlier, que realiza la detección y la manipulación (esta decisión de sustitutir por la media requiere de un análisis pormenorizado del origen o causa de estos valores atípicos).

```{r echo=TRUE, include=TRUE, warning=FALSE}
# Gráficos de cajas de todas las variables.
# En el gráfico se observa que muchas variables presentan outliers
boxplot(datos_pca,main="Análisis exploratorio de datos",
        xlab="Variables sociodemográficas",
        ylab="z-values",
        col=c(1:15))

# Función que detecta outliers y los sustituye por la media de la varaible
outlier<-function(data,na.rm=T){
  H<-1.5*IQR(data)
  data[data<quantile(data,0.25,na.rm = T)-H]<-NA
  data[data>quantile(data,0.75, na.rm = T)+H]<-NA
  data[is.na(data)]<-mean(data,na.rm=T)
  data
}

# Llamamos a la función outlier para cada variable que ha presentado outliers
datos_pca$znac_def<-outlier(datos_pca$znac_def)
datos_pca$zmortinf<-outlier(datos_pca$zmortinf)
datos_pca$zespvida<-outlier(datos_pca$zespvida)
datos_pca$zpib_cap<-outlier(datos_pca$zpib_cap)
datos_pca$zpoblac<-outlier(datos_pca$zpoblac)
datos_pca$zdensida<-outlier(datos_pca$zdensida)
datos_pca$zlog_pob<-outlier(datos_pca$zlog_pob)
datos_pca$zlogden<-outlier(datos_pca$zlogden)

# Comparamos los datos originales y los arreglados con respectivos boxplots 
par(mfrow=c(1,2))
# Boxplot de los datos originales
boxplot(datos_originales,main="Datos originales",
        xlab="Variables sociodemográficas",
        ylab="z-values",
        col=c(1:15))
# Boxplot de los datos corregidos.
boxplot(datos_pca,main="Datos sin outliers",
        xlab="Variables sociodemográficas",
        ylab="z-values",
        col=c(1:15))

``` 

Se aprecia que una ejecución de la función *outlier* no hace la limpieza de los valores atípicos (se necesitan varias). Se ha pedido al alumnado que mejore esta función para que el tratamiento sea satisfactorio en la primera ejecución. Una vez presentado se actualizará este guión.

A la vista de los resultados obtenidos en las secciones anteriores, **se está en disposición de realizar una reducción de la dimensión** mediante *ACP* ya que, no hay *NA*, los datos están correlados y se ha evitado la presencia de outliers.


### 3. **Reducción de la dimensión y resumen de la información numérica y gráfica de interés**
### 3.1. *Realización del ACP*
El siguiente código fuente realiza el ACP, obteniendo los vectores propios que generan cada componente, así como sus valores propios que corresponden a la varianza de cada una.

```{r echo=TRUE, include=TRUE, warning=FALSE}
# Realización del ACP
PCA<-prcomp(datos_pca, scale=T, center = T)

# El campo "rotation" del objeto "PCA" es una matriz cuyas columnas
# son los coeficientes de las componentes principales, es decir, el
# peso de cada variable en la correspondiente componente principal
PCA$rotation

# En el campo "sdev" del objeto "PCA" y con la función summary aplicada
# al objeto, obtenemos información relevante: desviaciones típicas de 
# cada componente principal, proporción de varianza explicada y acumulada.
PCA$sdev
summary(PCA)
```  

Los siguientes gráficos ilustran el comportamiento de la varianza explicada por cada componente principal así como el comportamiento de la varianza explicada acumulada.

```{r echo=TRUE, include=TRUE, warning=FALSE}
library("ggplot2")

# Proporción de varianza explicada
varianza_explicada <- PCA$sdev^2 / sum(PCA$sdev^2)
ggplot(data = data.frame(varianza_explicada, pc = 1:15),
       aes(x = pc, y = varianza_explicada, fill=varianza_explicada )) +
  geom_col(width = 0.3) +
  scale_y_continuous(limits = c(0,0.6)) + theme_bw() +
  labs(x = "Componente principal", y= " Proporción de varianza explicada")

# Proporción de varianza explicada acumulada
varianza_acum<-cumsum(varianza_explicada)
ggplot( data = data.frame(varianza_acum, pc = 1:15),
        aes(x = pc, y = varianza_acum ,fill=varianza_acum )) +
  geom_col(width = 0.5) +
  scale_y_continuous(limits = c(0,1)) +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Proporción varianza explicada acumulada")
```  

### 3.2. *Selección del número de componentes principales óptimo*

Existen diferentes métodos que ayudan a elegir el número adecuado de componentes principales con las que es suficiente analizar el problema bajo estudio.

+ Métodos del codo (Cuadras, 2007, etc.). **Ejercicio**: buscar información (voluntario)
+ A criterio del investigador que elige un porcentaje mínimo de varianza explicada por las componentes principales (no es fiable porque puede dar más de las necesarias.
+ Regla de Abdi et al. (2010). Se promedia las varianzas explicadas por la componentes principales y se selecciona aquellas cuya proporción de varianza explicada supera la media.



```{r echo=TRUE, include=TRUE, warning=FALSE}
PCA$sdev^2
mean(PCA$sdev^2)
``` 

A la vista de los resultados, en este caso, se eligen tan solo cuatro direcciones principales que tal y como se puede verque acumulan casi un $80\%$ de varianza explicada.

Cada componente principal se obtiene de forma sencilla como combinación lineal de todas las variables con los coeficientes que indican las columnas de la matriz de rotación. **Ejercicio voluntario**: escribir la expresión analítica de cada componente principal.

```{r echo=TRUE, include=TRUE, warning=FALSE}
head(PCA$x,n=4)
``` 

### 3.3. *Distintas salidas gráficas de interés*
Los siguientes gráficos muestran la **comparativa entre distintas componentes principales** mediante una proyección al plano sobre cada dos componentes. En esta representación se aprecia cuáles de las variables originales tienen mayor o menor peso en cada una de las componentes enfrentadas.

```{r echo=TRUE, include=TRUE, warning=FALSE}
# La siguiente línea se ejecuta una vez siempre que no esté instalado el paquete
# install.packages("factoextra")

# Carga del paquete "factorextra" si está instalado
library("factoextra")

# Comparativa entre la primera y segunda componente principal
fviz_pca_var(PCA,
             repel=TRUE,col.var="cos2",
             legend.title="Distancia")+theme_bw()

# Comparativa entre la primera y tercera componente principal 
fviz_pca_var(PCA,axes=c(1,3),
             repel=TRUE,col.var="cos2",
             legend.title="Distancia")+theme_bw()

# Comparativa entre la segunda y tercera componente principal
fviz_pca_var(PCA,axes=c(2,3),
             repel=TRUE,col.var="cos2",
             legend.title="Distancia")+theme_bw()

``` 


Es posible también **representar las observaciones** de los objetos junto con las componentes principales mediante la orden *contrib* de la función *fviz_pca_ind* anterior, así como identificar con colores aquellas observaciones que mayor varianza explican.

```{r echo=TRUE, include=TRUE, warning=FALSE}
# Observaciones en la primera y segunda componente principal
fviz_pca_ind(PCA,col.ind = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel=TRUE,legend.title="Contrib.var")+theme_bw()

# Observaciones en la primera y tercera componente principal
fviz_pca_ind(PCA,axes=c(1,3),col.ind = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel=TRUE,legend.title="Contrib.var")+theme_bw()

# Observaciones en la segunda y tercera componente principal
fviz_pca_ind(PCA,axes=c(2,3),col.ind = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel=TRUE,legend.title="Contrib.var")+theme_bw()

``` 

Finalmente se puede obtener una **representación conjunta de variables y observaciones** que relaciona visualmente las posibles relaciones entre las observaciones, las contribuciones de los individuos a las varianzas  y el peso de las variables en cada componente principal.

```{r echo=TRUE, include=TRUE, warning=FALSE}
# Variables y observaciones en las 1?  y 2? componente principal
fviz_pca(PCA,
         alpha.ind ="contrib", col.var = "cos2",col.ind="seagreen",
         gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
         repel=TRUE,
         legend.title="Distancia")+theme_bw()

# Variables y observaciones en las 1?  y 3? componente principal
fviz_pca(PCA,axes=c(1,3),
         alpha.ind ="contrib", col.var = "cos2",col.ind="seagreen",
         gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
         repel=TRUE,
         legend.title="Distancia")+theme_bw()

# Variables y observaciones en las 1?  y 2? componente principal
fviz_pca(PCA,axes=c(1,2),
         alpha.ind ="contrib", col.var = "cos2",col.ind="seagreen",
         gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
         repel=TRUE,
         legend.title="Distancia")+theme_bw()

``` 

### **Referencias**

1.- The R Project for Statistical Computing (https://www.r-project.org/) (Accedido el 1 de octubre de 2022).
